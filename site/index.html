
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html>
<head>
<title>LabROSA - About</title>
<style type="text/css">

@import url(http://fonts.googleapis.com/css?family=Open+Sans);
body 
{
    background: #ffebcd;
    font: normal 100% 'Open+Sans', sans-serif;
    margin: 0;
    color: #555;
}

body > *
{
    width: 890px;
    padding: 20px;
    margin: 16px auto;
    background: white;
}

a
{
    color: #28D;
    text-decoration: none;
}

#header
{
    position: relative;
}

#header h1
{
    display: inline;
    font-size: 380%;
}

#menu
{
    font-size: 120%;
    word-spacing: 20px;
    text-align: right;
    position: absolute;
    right: 30px;
    bottom: 24px;
}

.topRow
{
    background-color: #000000;
    font-weight: bold;
    text-align: center;
    color: #FFFFFF;
}

#peopleTable tr td
{
    padding: 8px;
}

#peopleTable
{
    border-spacing: 0px;
}

</style>
<meta http-equiv="Content-Type" content="text/html;charset=UTF-8">
</head>
<body>
<div id="header">
<!-- <h1>Lab<font style="color:#FF00FF">ROSA</font></h1>//-->
<img src="/files/labROSA-header.png" style="height: 70px" />
<div id="menu">
<a href="/">About</a>
<a href="/people">People</a>
<a href="/projects">Projects</a>
<a href="/publications">Publications</a>
<a href="/contact">Contact</a>
</div>
</div>

<div id ="main">

<h2>About</h2>


<p>The Laboratory for the Recognition and Organization of Speech and Audio (<b>Lab<font color="#d773b4">ROSA</font></b>) conducts research into automatic means of extracting useful information from sound.
Our vision is of an intelligent 'machine listener', able to interpret live or recorded sound of any type in terms of the descriptions and abstractions that would make sense to a human listener.
Our research areas include:
</p>

<ul>
  <li>speech, to extract the words, prosodics, speaker characteristics, etc.
  <li>music, including transcription, classification, and similarity estimation
  <li>environmental sound, such as everyday acoustic ambiences, or even from atypical environments including underwater
  <li>sound mixtures, composed of any or all of the above, where the challenge is extracting whatever information is available when observations are partial or obscured.
</ul>

<p>Applications for automatic high-level sound analysis to be developed include:</p>

<ul>
  <li>indexing, summarization and searching within large audio archives,
  such as recorded broadcasts, film catalogs, personal recording devices
  etc.
  <li>intelligent interaction technologies that have an 'awareness' of their
  acoustic environment, and can react appropriately
  <li>automatic monitoring devices e.g. for rapid response to emergencies
  in public complexes.
  <li>intelligent handling of audio and music content, including content-based
  retrieval, annotation, and recommendation.
</ul>

</div>
</body>
</html>